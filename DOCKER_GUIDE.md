# üê≥ Guide de Dockerisation : Smart Port Hub

Ce document explique comment nous avons conteneuris√© l'ensemble de la plateforme pour garantir un d√©ploiement fiable et reproductible, peu importe la machine (Windows, Mac ou Linux).

---

## üèóÔ∏è 1. Architecture Multi-Conteneurs

Nous utilisons **Docker Compose** pour orchestrer trois services qui communiquent entre eux dans un r√©seau priv√© virtuel :

1.  **`postgres`** : La base de donn√©es (image l√©g√®re Alpine).
2.  **`backend`** : L'API NestJS (Node.js).
3.  **`ai-service`** : Le microservice d'IA (Python/FastAPI).

---

## üìÑ 2. Le Backend NestJS (`Dockerfile` √† la racine)

Nous avons utilis√© un **"Multi-Stage Build"** (construction en plusieurs √©tapes) :

*   **√âtape 1 (Builder)** : Utilise une image Node compl√®te pour compiler le TypeScript en JavaScript (`npm run build`) et g√©n√©rer le client Prisma.
*   **√âtape 2 (Production)** : On ne garde que les fichiers compil√©s (`dist/`) et les `node_modules`.
*   **Pourquoi ?** Cela permet d'avoir une image finale beaucoup plus petite et s√©curis√©e (pas de code source, pas d'outils de compilation).

---

## üìÑ 3. Le Service IA (`src/modules/ai_service/Dockerfile`)

C'est ici que Docker nous a sauv√© !
*   **Le probl√®me** : Installer certaines biblioth√®ques comme `scikit-learn` sur Windows peut √©chouer √† cause des outils de compilation C++.
*   **La solution Docker** : On utilise une image **Linux (Python-slim)**. Docker installe les d√©pendances √† l'int√©rieur de ce syst√®me Linux propre, ce qui garantit que l'IA fonctionne instantan√©ment chez n'importe qui.
*   **Installation** : On installe `build-essential` temporairement pour compiler les libs Python, puis on nettoie pour rester l√©ger.

---

## ‚öôÔ∏è 4. Orchestration (`docker-compose.yml`)

Le fichier `docker-compose.yml` est le chef d'orchestre :

### A. R√©seautage & Communication
Les services se parlent par leurs noms de domaine internes :
*   Le Backend contacte l'IA via `http://ai-service:8000`.
*   L'IA contacte le Backend via `http://backend:3000/api`.

### B. Automatisation au d√©marrage
Pour le service `backend`, nous avons automatis√© trois √©tapes critiques dans la commande de lancement :
1.  `npx prisma db push` : Synchronise le sch√©ma avec la base Postgres.
2.  `npx prisma db seed` : Remplit la base avec les donn√©es de test (Ports, Terminaux).
3.  `node dist/main.js` : Lance l'application.

### C. Persistance des donn√©es
Nous utilisons un **Volume** (`postgres_data`) pour que, m√™me si tu √©teins tout, les donn√©es de ta base de donn√©es ne soient pas perdues.

---

## üõ†Ô∏è 5. R√©sum√© des avantages pour le JURY

*   **Portabilit√©** : "Une seule commande (`docker compose up`) configure TOUT le syst√®me."
*   **Isolation** : "L'IA en Python n'interf√®re pas avec le Backend en Node.js."
*   **Production-Ready** : "Nos images sont optimis√©es (Multi-stage) et pr√™tes √† √™tre d√©ploy√©es sur un serveur cloud."
*   **Fiabilit√©** : "Le processus de migration et de seeding est automatique, √©vitant les erreurs humaines de configuration."

---
*Ce syst√®me permet de passer d'un code local √† une application distribu√©e capable de tourner n'importe o√π.*
